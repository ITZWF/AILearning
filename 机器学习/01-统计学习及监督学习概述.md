<p align="center"><font color="green" size=4>Chapter 1. 统计学习及监督学习概述</font></p>

### 1.1 统计学习

 	监督学习, 无监督学习, 强化学习等

### 1.2 统计学习的分类

#### 1.2.1 基本分类

 1. 监督学习

    输入空间 --> X ∈ R^n, 输入的特征维度

    特征空间 --> X所在的欧式空间

    输出空间 --> Y所在的欧式空间

    联合概率分布 --> P(X, Y)

    假设空间 --> Y = f(X), f映射的空间

    ```mermaid
    stateDiagram
    	XY训练集合 --> 学习系统
    	学习系统 --> 模型: Y = f(X)
    	Xi --> 预测系统
    	预测系统 --> Yi
    	预测系统 --> 模型
    	模型 --> 预测系统
    ```

    

    2. 无监督学习

       Z = g(X), Z隐式空间, 大意是拟合大多数数据服从某个特殊的分布, 比如大多数聚类(Kmeans等)假设服从欧式空间最近几何分布

    3. 强化学习

       马尔科夫决策(图), 奖励惩罚机制

    4. 半监督与主动学习

    #### 1.2.2 按模型分类

    1. 概率模型和非概率模型

       概率模型: P(y|x), 朴素贝叶斯, HMM, CRF...

       非概率模型: Y = f(X), 大多数深度学习, 感知机, SVM...

    2. 线性和非线性

       线性: y = f(x)

    3. 参数化和非参数化

       参数化: 固定维度可分

       非参数化: 固定维度不可分

    #### 1.3 统计学习方法的三要素

    1. 模型 Y = f(X)
    2. 策略 loss最小化
    3. 算法 数值求解方法

    #### 1.4 模型评估和选择

    ​	训练误差和测试误差

    ​	过拟合和模型选择

    #### 1.5 正则化与交叉验证

    ​	正则化  +惩罚项,   正则化是L2范数

    ​	交叉验证

    #### 1.6 泛化能力

    ​	模型对未知数据的预测能力

    #### 1.7 生成和判别模型

    ​	生成模型: P(Y|X) = P(X, Y) / P(X), 朴素贝叶斯, HMM ...

    ​	判别模型: Y = f(X), 直接学习到

    #### 1.8 监督学习应用

    	1. 分类问题: P, R, F1
    	1. 标注问题: HMM, CRF
    	1. 回归问题: 最小二乘法