<p align="center"><font color="green" size=4>Chapter 5. 决策树</font></p>

### 5.1 决策树模型和学习

1. 决策树: 树形结构, 由结点, 有向边组成, 结点: 内部结点和叶结点
2. if then规则
3. 决策树与条件概率分布: 空间集合的划分
4. 决策树学习

### 5.2 特征选择

1. 特征选择问题
2. 信息增益: 

​	熵: P(X=xi) = pi, H(X) = -∑pilog(pi)

​	H(Y|X) = ∑piH(Y|X=xi)

​	信息增益: g(D, A) = H(D) - H(D|A)

​	信息增益算法:  

​	(1) 计算数据集D经验熵H(D)

​	(2) 计算特征A对数据集D的经验熵H(D|A)

​	(3) 计算信息增益

3. 信息增益比
   1. gr(D, A) = g(D|A) / Ha(D)

### 5.3 决策树的生成

1. ID3算法: 信息增益最大的分子结点
2. C4.5算法:   信息增益比最大的分子结点

### 5.4 决策树的剪枝

决策树的损失函数和参数α决定

### 5.5 CART算法

